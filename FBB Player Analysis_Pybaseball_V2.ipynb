{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962394fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The purpose of this script is to:\n",
    "#take league-specific information on player ownership and free agents from my Yahoo fantasy baseball league\n",
    "#pair this with some advanced metrics from the pybaseball python package\n",
    "#output a dataset with this information to help identify where opportunities may exist to pick up players where underlying numbers\n",
    "#are performing well and they are available via free agency or trade with other fantasy teams\n",
    "#yahoo fantasy API documentation: https://developer.yahoo.com/fantasysports/guide/\n",
    "\n",
    "import http.client\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import math\n",
    "import pybaseball as pb\n",
    "import re\n",
    "import os\n",
    "\n",
    "yr = 2025\n",
    "output_folder = os.environ['output_path'] \n",
    "\n",
    "#this is for manual mapping purposes. For some reason some players dont have a fangraphs ID in the playerid_lookup function result which\n",
    "#breaks my joins. There were 88 players in this situation in April 2025. \n",
    "#Hopefully the playerid_lookup function gets updated to close this gap\n",
    "#but rather than continue to miss out on critical stats from certain players I created a manual mapping table that I can use\n",
    "#when the fangraphs ID from the playerid_lookup function does not return a valid ID to get an ID to join with and\n",
    "#reduce the players in the final data set that I don't get data for\n",
    "df_fg_map = pd.read_csv(os.getcwd() + \"\\\\FangraphID_Map.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87942a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 11:28:00,041 DEBUG] [yahoo_oauth.oauth.__init__] Checking \n",
      "[2025-05-08 11:28:00,042 DEBUG] [yahoo_oauth.oauth.token_is_valid] ELAPSED TIME : 133899.12497377396\n",
      "[2025-05-08 11:28:00,044 DEBUG] [yahoo_oauth.oauth.token_is_valid] TOKEN HAS EXPIRED\n",
      "[2025-05-08 11:28:00,045 DEBUG] [yahoo_oauth.oauth.refresh_access_token] REFRESHING TOKEN\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myahoo_fantasy_api\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myfa\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#connect to yahoo API, this environment variable points to a json file that has all the API Oauth2 authentication information\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m sc \u001b[38;5;241m=\u001b[39m OAuth2(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, from_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPI_OAUTH_YFNTSY\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#get the game object, we are looking at mlb information\u001b[39;00m\n\u001b[0;32m     16\u001b[0m gm \u001b[38;5;241m=\u001b[39m yfa\u001b[38;5;241m.\u001b[39mGame(sc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\Lib\\site-packages\\yahoo_oauth\\oauth.py:239\u001b[0m, in \u001b[0;36mOAuth2.__init__\u001b[1;34m(self, consumer_key, consumer_secret, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, consumer_key, consumer_secret, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28msuper\u001b[39m(OAuth2, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moauth2\u001b[39m\u001b[38;5;124m'\u001b[39m, consumer_key, consumer_secret, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\Lib\\site-packages\\yahoo_oauth\\oauth.py:94\u001b[0m, in \u001b[0;36mBaseOAuth.__init__\u001b[1;34m(self, oauth_version, consumer_key, consumer_secret, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccess_token\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefresh_token\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_is_valid():\n\u001b[1;32m---> 94\u001b[0m         data\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefresh_access_token())\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     data\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandler())\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\Lib\\site-packages\\yahoo_oauth\\oauth.py:209\u001b[0m, in \u001b[0;36mBaseOAuth.refresh_access_token\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    205\u001b[0m     headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_oauth2_headers()\n\u001b[0;32m    207\u001b[0m     raw_access \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moauth\u001b[38;5;241m.\u001b[39mget_raw_access_token(\n\u001b[0;32m    208\u001b[0m         data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefresh_token\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefresh_token, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mredirect_uri\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_uri, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrant_type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefresh_token\u001b[39m\u001b[38;5;124m'\u001b[39m}, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m--> 209\u001b[0m     credentials\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moauth2_access_parser(raw_access))\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m credentials\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\Lib\\site-packages\\yahoo_oauth\\oauth.py:172\u001b[0m, in \u001b[0;36mBaseOAuth.oauth2_access_parser\u001b[1;34m(self, raw_access)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moauth2_access_parser\u001b[39m(\u001b[38;5;28mself\u001b[39m, raw_access):\n\u001b[0;32m    170\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse oauth2 access\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m     parsed_access \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(raw_access\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccess_token \u001b[38;5;241m=\u001b[39m parsed_access[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccess_token\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type \u001b[38;5;241m=\u001b[39m parsed_access[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "#This module is establishing a connection to the Yahoo Fantasy Sports API and setting up variables for my league and team\n",
    "#https://yahoo-fantasy-api.readthedocs.io/en/latest/yahoo_fantasy_api.html - references\n",
    "\n",
    "#Oauth instructions\n",
    "#https://pypi.org/project/yahoo-oauth/\n",
    "#https://developer.yahoo.com/apps/2YZSzEV6/\n",
    "\n",
    "#Import any packages we need\n",
    "from yahoo_oauth import OAuth2\n",
    "import yahoo_fantasy_api as yfa\n",
    "\n",
    "#connect to yahoo API, this environment variable points to a json file that has all the API Oauth2 authentication information\n",
    "sc = OAuth2(None, None, from_file = os.environ['API_OAUTH_YFNTSY'])\n",
    "\n",
    "#get the game object, we are looking at mlb information\n",
    "gm = yfa.Game(sc, 'mlb')\n",
    "\n",
    "#Set the team and league specific variables\n",
    "league_id = gm.game_id() + '.l.' + str(os.environ['YFNTSY_LGID'])\n",
    "teamkey = league_id + os.environ['YFNTSY_TMID'] #My team\n",
    "\n",
    "#create a variable to get the current league, then set a variable for my team's key\n",
    "lg = gm.to_league(league_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b24b2d-5617-45db-9425-f7c3cfdb8b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Step 1a: Get the free agent data\n",
    "\n",
    "#set some variables to start getting all of the free agents\n",
    "#Update 6/16/23 - added \"OF\" because Seiya Suzuki was not showing when I pulled batters or \"Util\" players. Didn't notice other players missing for now\n",
    "lsPos = ['SP','B','OF']\n",
    "df_fa_all = pd.DataFrame()\n",
    "lsFA = []\n",
    "\n",
    "#Loop through the different positions\n",
    "for l in lsPos:\n",
    "    \n",
    "    #Get the json of the free agents and put it in a dataframe\n",
    "    fa = lg.free_agents(l)\n",
    "    \n",
    "    #append the new player info to the existing list\n",
    "    lsFA = lsFA + fa\n",
    "\n",
    "#convert the player data to a dataframe\n",
    "df_fa_all = pd.DataFrame.from_records(lsFA)\n",
    "\n",
    "#print a sample to see what we have\n",
    "df_fa_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d32dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The purpose of this function is to look in a manually maintained exception table for fangraph ID's\n",
    "#for some reason there are some fangraphs ID's that don't show up correctly in the pybaseball playerid_lookup function, despite these ID's existing\n",
    "#I created a file that maps a different ID to the fangraphs ID for the individuals I can identify in this situation\n",
    "#We will always look the ID up in the playerid_lookup function, but if we can't find a valid ID there this function will try to find it\n",
    "def fangraphs_m_lkup(fg_map, mlbid, fail_val):\n",
    "    \n",
    "    #look up the record for the input mlb ID\n",
    "    r = fg_map[fg_map['IDmlb'] == mlbid]\n",
    "\n",
    "    #if there is any record there, return the fangraph ID, otherwise return whatever value we wanted if it failed\n",
    "    if r.shape[0] > 0:\n",
    "        return(r.iloc[0]['IDfg'])\n",
    "    else:\n",
    "        return(fail_val)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1b: modify the free agent data once we have defined it in the previous step\n",
    "\n",
    "#Get rid of the duplicates\n",
    "df_fa_all = df_fa_all.drop_duplicates(subset=['player_id'])\n",
    "\n",
    "#Add some new columns that we will populate below\n",
    "df_fa_all['name'] = None\n",
    "df_fa_all['owner'] = 'FA'\n",
    "\n",
    "#The index variable is jacked up because we stitched all of these datafames together. This should fix it.\n",
    "df_fa_all = df_fa_all.reset_index()\n",
    "\n",
    "#Loop through each row of the dataframe, pull each player ID and populate the addiitonal player attribute columns we created above\n",
    "for index, row in df_fa_all.iterrows():\n",
    "    \n",
    "    #get the player detail using the player ID based on what iteration of the loop we are on\n",
    "    pdtl = lg.player_details(row.loc['player_id'])[0]\n",
    "\n",
    "    #update the player detail in the appropriate column in our orignal dataframe\n",
    "    df_fa_all.at[index, 'name'] = pdtl['name']['full']\n",
    "\n",
    "    #We need to slow this down to not make too many calls in a row but trying to do that less frequently\n",
    "    if index/40 == math.floor(index/40) and index > 0:\n",
    "        \n",
    "        #We need to slow this down to not make too many calls in a row but trying to do that less frequently\n",
    "        time.sleep(60)\n",
    "        \n",
    "        #let the user know what's going on\n",
    "        print(\"Still going ... we are at loop number {}\".format(index)) #see how we are doing\n",
    "        \n",
    "#Let them know we are finally done\n",
    "print(\"done with loop, Victory!\")\n",
    "\n",
    "#drop this index column so it aligns with the 'owned' dataframe below\n",
    "df_fa_all = df_fa_all.drop('index',axis=1)\n",
    "\n",
    "#split into pitcher and batter players\n",
    "df_fa_p = df_fa_all[df_fa_all['position_type'] == 'P']\n",
    "df_fa_b = df_fa_all[df_fa_all['position_type'] == 'B']\n",
    "\n",
    "#print a sample to see what we have\n",
    "df_fa_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43368971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 - get data from pybaseball on pitchers and hitters\n",
    "#Documentation: https://github.com/jldbc/pybaseball/tree/master/docs\n",
    "\n",
    "#get the pitching and batting data\n",
    "df_pitcher_stat = pb.pitching_stats(yr, qual='n')\n",
    "df_batter_stat = pb.batting_stats(yr, qual='n')\n",
    "\n",
    "#if I'm adding something new I may want to list all of the columns to find what I want to add to my list of stats\n",
    "#print(list(df_pitcher_stat.columns))\n",
    "#print(list(df_batter_stat.columns))\n",
    "\n",
    "#limit pitcher stats to only the fields we want\n",
    "df_pitcher_stat_final = df_pitcher_stat[['IDfg','Name','Team','W','ERA','WHIP','GS','SO','IP','SV','HLD','HR','BB','K/9','K/BB','BABIP','BABIP+','FIP','xFIP','Barrel%','HardHit%','Contact%']]\n",
    "\n",
    "#Limit batter stats to only what we want\n",
    "df_batter_stat_final = df_batter_stat[['IDfg','Name','Team','PA','R','HR','RBI','SO','K%','OBP','OBP+','SB','CS','OPS','BB','O-Swing%','Z-Swing%','BABIP','BABIP+','Barrel%','HardHit%','maxEV']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ffc8a4-2b77-4479-90da-14c7997600a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function centralizes mapping a data set from Yahoo to stats from PyBaseball for a pitcher\n",
    "#I put this into it's own function for 2 reasons.\n",
    "#one is because I needed to use the same mechanism in 2 independent locations, one for free agents and one for owned players\n",
    "#the second is since this has to map based on name if I run into something not mapping correctly I can force the mapping in the function. \n",
    "def YahooPlayerMap(df, yr):\n",
    "    \n",
    "    #Transfer the data in the input dataframe to a new variable\n",
    "    df_final = df.copy()\n",
    "    \n",
    "    #remove any middle initials with this regex pattern: [A-z]+\\.\n",
    "    df_final['name'] = df_final['name'].str.replace(r'\\s+[A-z]+\\.', '', regex=True)\n",
    "    \n",
    "    #create a dataframe with the split names so we can do some cleanup before it is integrated to the broader dataframe\n",
    "    df_nm = df_final['name'].str.split(' ', expand = True)\n",
    "\n",
    "    #do some cleanup\n",
    "    df_nm.fillna('',inplace = True) #convert na's to '' because it messes up the concatenation\n",
    "    df_nm = df_nm.replace('(Batter)','') #convert (Batter) to '' because Ohtani messes this up\n",
    "    df_nm = df_nm.replace('(Pitcher)','') #convert (Pitcher) to '' because Ohtani messes this up\n",
    "\n",
    "    #loop through the columns\n",
    "    for i in df_nm.columns:\n",
    "\n",
    "        #we want to ignore columns 0 and 1, so if it's above 1 that means we have a last name with spaces in it (De La Cruz) that was separated into multiple columns\n",
    "        #So we want to concatenate it onto the last name with a space\n",
    "        if i > 1:\n",
    "            df_nm[1] = df_nm[1] + ' ' + df_nm[i]\n",
    "    \n",
    "    #strip out any blank spaces we just added by accident\n",
    "    df_nm[1] = df_nm[1].str.strip()\n",
    "    \n",
    "    #now limit to only the first 2 columns which should be a clean first and last name\n",
    "    df_nm = df_nm[[0,1]]\n",
    "    \n",
    "    #Split the player names by firstname and lastname because that's what we need to join data\n",
    "    #df_final[['FirstName', 'LastName']] = df_final['name'].str.split(' ', expand = True)[[0,1]]  #old version - modified slightly for version 3.11, had to add the [[0,1]] because some names were split into a third column\n",
    "    df_final[['FirstName', 'LastName']] = df_nm\n",
    "\n",
    "    #Add dummy columns to hold the IDs\n",
    "    df_final['IDfg'] = 'NO DATA'\n",
    "    df_final['IDmlb'] = 'NO DATA'\n",
    "    df_final['ID_FNM'] = 'NO DATA'\n",
    "    df_final['ID_LNM'] = 'NO DATA'\n",
    "    df_final['NumPlyr'] = 'NO DATA'\n",
    "    \n",
    "    #loop through each row and get the fangraphs ID for each player\n",
    "    for index, row in df_final.iterrows():\n",
    "        \n",
    "        #get the player ID.  The fuzzy=true will allow us to still find the player if the name isn't an exact match\n",
    "        #We then grab the value in the first row. This is risky but I don't know a better way to do it right now\n",
    "        df_plyr = pb.playerid_lookup(row['LastName'],row['FirstName'], fuzzy=True)\n",
    "        \n",
    "        #filter for only player that played this year or last and reset the index so we all the index numbers make sense\n",
    "        df_plyr = df_plyr[df_plyr.mlb_played_last.isin([yr,yr-1])]\n",
    "        df_plyr = df_plyr.reset_index(drop=True)\n",
    "\n",
    "        #append this to the full df_fa_p dataframe only if we returned valid results\n",
    "        if df_plyr.shape[0] > 0:\n",
    "            \n",
    "            #if the fangraphs ID is -1 see if we can get a valid ID in the manual mapping table\n",
    "            if df_plyr['key_fangraphs'][0] == -1:\n",
    "                fg = fangraphs_m_lkup(df_fg_map, df_plyr['key_mlbam'][0], df_plyr['key_fangraphs'][0])\n",
    "\n",
    "            else:\n",
    "                fg = df_plyr['key_fangraphs'][0]\n",
    "            \n",
    "            #set the ID values\n",
    "            df_final.loc[index,['IDfg']] = fg\n",
    "            df_final.loc[index,['IDmlb']] = df_plyr['key_mlbam'][0]\n",
    "\n",
    "            #These two fields are captured only to give a check to see which name we grabbed the ID for in case something doesn't look right\n",
    "            df_final.loc[index, ['ID_FNM']] = df_plyr['name_first'][0]\n",
    "            df_final.loc[index, ['ID_LNM']] = df_plyr['name_last'][0]\n",
    "            \n",
    "            #return how many rows we got in case we got multiple and had to make an assumption on who to pull\n",
    "            df_final.loc[index, ['NumPlyr']] = df_plyr.shape[0]\n",
    "                \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a1ab01-5fcd-4fb9-80d6-a1e366f1a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: build out ownership of players and pair with Fangraphs data. Used for 2 purposes:\n",
    "#1) look at my team and how underlying numbers imply they are performing, find opportunities to hold or trade/cut\n",
    "#2) look for trade candidates from other teams, underperforming but underlying numbers look strong\n",
    "\n",
    "#Get the result of the taken_players API call\n",
    "p = lg.taken_players()\n",
    "\n",
    "#create a list to hold the owner data\n",
    "ls_o = []\n",
    "cnt = 0\n",
    "\n",
    "#Loop through all the owned players\n",
    "for i in p:\n",
    "    \n",
    "    #add one to the count\n",
    "    cnt += 1\n",
    "    \n",
    "    #Get the team ownership information\n",
    "    o = lg.ownership([i['player_id']])\n",
    "    \n",
    "    #Append each individual row onto this list\n",
    "    ls_o.append({'player_id' : i['player_id'],\n",
    "                 'name' : i['name'], \n",
    "                 'position_type' : i['position_type'], \n",
    "                 'eligible_positions' : i['eligible_positions'], \n",
    "                 'percent_owned' : i['percent_owned'],\n",
    "                 'status' : i['status'], \n",
    "                 'owner' : o[str(i['player_id'])]['owner_team_name']})\n",
    "    \n",
    "    #We need to slow this down to not make too many calls in a row but trying to do that less frequently\n",
    "    if cnt/40 == math.floor(cnt/40):\n",
    "        \n",
    "        #We need to slow this down to not make too many calls in a row but trying to do that less frequently\n",
    "        time.sleep(30)\n",
    "        \n",
    "        #let the user know what's going on\n",
    "        print(\"Still going ... we are at loop number {} of {}\".format(cnt, len(p))) #see how we are doing\n",
    "        \n",
    "#convert the list to a dataframe\n",
    "dfOA = pd.DataFrame.from_records(ls_o)\n",
    "\n",
    "#Let the user know we got this far\n",
    "print(\"Done with Owned Players/ Owner Mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a64e05-b37f-42af-b38d-f726341383df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Union each of the two player dataframes together\n",
    "\n",
    "#Append the FA pitcher data with the owned pitcher data\n",
    "#df_pitcher_all = df_fa_p.append(dfOA[dfOA['position_type'] == 'P']).reset_index()  #OLD - trying to get away from .append because it is deprecating\n",
    "df_pitcher_all = pd.concat([df_fa_p, dfOA[dfOA['position_type'] == 'P']]).reset_index()\n",
    "\n",
    "#Append the FA batter data with the owned batter data\n",
    "#df_batter_all = df_fa_b.append(dfOA[dfOA['position_type'] == 'B']).reset_index()    #OLD - trying to get away from .append because it is deprecating\n",
    "df_batter_all = pd.concat([df_fa_b, dfOA[dfOA['position_type'] == 'B']]).reset_index()\n",
    "\n",
    "#print a sample to see what it looks like\n",
    "print(df_batter_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ccc165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4 - join the pitcher data together, output the result\n",
    "\n",
    "#use this function to pull the ID's of pitchers we want to grab data for\n",
    "df_pitcher_all_f = YahooPlayerMap(df_pitcher_all,yr)\n",
    "\n",
    "#join the two data sets on the fangraphs ID\n",
    "df_pitcher_all_f = df_pitcher_all_f.merge(df_pitcher_stat_final, how='left',on='IDfg')\n",
    "\n",
    "#Sort by percent owned so we see the more popular players first\n",
    "df_pitcher_all_f = df_pitcher_all_f.sort_values(by=['owner','percent_owned'], ascending=False)\n",
    "\n",
    "#Drop this to Excel so it's easier to read\n",
    "df_pitcher_all_f.to_excel(output_folder + \"Pitchers_All.xlsx\", freeze_panes=(1, 1), index=False) #Removed timestamp portion: \" + \"_\" + datetime.today().strftime('%Y%m%d') + \"\n",
    "\n",
    "#Let the user know we are done with this step\n",
    "print(\"Pitchers done. Victory!\", df_pitcher_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfe33f1-b0ea-41cf-96ae-818f6dd17284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5 - join the batter data together, output the result\n",
    "\n",
    "#use this function to pull the ID's of pitchers we want to grab data for\n",
    "df_batter_all_f = YahooPlayerMap(df_batter_all,yr)\n",
    "\n",
    "#join the two data sets on the fangraphs ID\n",
    "df_batter_all_f = df_batter_all_f.merge(df_batter_stat_final, how='left',on='IDfg')\n",
    "\n",
    "#Sort by percent owned so we see the more popular players first\n",
    "df_batter_all_f = df_batter_all_f.sort_values(by=['owner','percent_owned'], ascending=False)\n",
    "\n",
    "#Drop this to Excel so it's easier to read\n",
    "df_batter_all_f.to_excel(output_folder + \"Batters_All.xlsx\", freeze_panes=(1, 1), index=False) #Removed timestamp portion: \" + \"_\" + datetime.today().strftime('%Y%m%d') + \"\n",
    "\n",
    "#Let the user know we are done with this step\n",
    "print(\"Batters done. Victory!\", df_pitcher_all.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
